{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076e0c79-1937-4356-95b6-1ed73f9dfd61",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Investigate the graph data loader, in order to better understand the structure of the data. I will do this by copying and pasting the code in `GraphRNN/main.py` and running line by line in this notebook. This will allow me to get a hands-on look at the data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbef618-6a44-48a7-949c-df776715edac",
   "metadata": {},
   "source": [
    "# main\n",
    "\n",
    "The code from `main.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc32c202-890c-486f-850c-10bf7a6604df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21165f22-ec74-44e0-85d6-1d004b42d05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 1\n",
      "File name prefix GraphRNN_RNN_grid_4_128_\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda)\n",
    "print('CUDA', args.cuda)\n",
    "print('File name prefix',args.fname)\n",
    "# check if necessary directories exist\n",
    "if not os.path.isdir(args.model_save_path):\n",
    "    os.makedirs(args.model_save_path)\n",
    "if not os.path.isdir(args.graph_save_path):\n",
    "    os.makedirs(args.graph_save_path)\n",
    "if not os.path.isdir(args.figure_save_path):\n",
    "    os.makedirs(args.figure_save_path)\n",
    "if not os.path.isdir(args.timing_save_path):\n",
    "    os.makedirs(args.timing_save_path)\n",
    "if not os.path.isdir(args.figure_prediction_save_path):\n",
    "    os.makedirs(args.figure_prediction_save_path)\n",
    "if not os.path.isdir(args.nll_save_path):\n",
    "    os.makedirs(args.nll_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c49cbc-130b-43cb-b2fb-0efc1872e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "# logging.basicConfig(filename='logs/train' + time + '.log', level=logging.DEBUG)\n",
    "if args.clean_tensorboard:\n",
    "    if os.path.isdir(\"tensorboard\"):\n",
    "        shutil.rmtree(\"tensorboard\")\n",
    "configure(\"tensorboard/run\"+time, flush_secs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f2f59d-82fd-4eac-9ed3-52272b456e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = create_graphs.create(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d569d46-c925-4d1a-b3ec-e65a03a5032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets\n",
    "random.seed(123)\n",
    "shuffle(graphs)\n",
    "graphs_len = len(graphs)\n",
    "graphs_test = graphs[int(0.8 * graphs_len):]\n",
    "graphs_train = graphs[0:int(0.8*graphs_len)]\n",
    "graphs_validate = graphs[0:int(0.2*graphs_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7c8eb0-4042-4e7e-bb9d-1fc98e8686e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_validate_len 199.5\n",
      "graph_test_len 215.0\n"
     ]
    }
   ],
   "source": [
    "graph_validate_len = 0\n",
    "for graph in graphs_validate:\n",
    "    graph_validate_len += graph.number_of_nodes()\n",
    "graph_validate_len /= len(graphs_validate)\n",
    "print('graph_validate_len', graph_validate_len)\n",
    "\n",
    "graph_test_len = 0\n",
    "for graph in graphs_test:\n",
    "    graph_test_len += graph.number_of_nodes()\n",
    "graph_test_len /= len(graphs_test)\n",
    "print('graph_test_len', graph_test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d4ce021-28f3-4b8e-a36c-57ccb357fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total graph num: 100, training set: 80\n",
      "max number node: 361\n",
      "max/min number edge: 684; 180\n",
      "max previous node: 40\n"
     ]
    }
   ],
   "source": [
    "args.max_num_node = max([graphs[i].number_of_nodes() for i in range(len(graphs))])\n",
    "max_num_edge = max([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "min_num_edge = min([graphs[i].number_of_edges() for i in range(len(graphs))])\n",
    "\n",
    "# args.max_num_node = 2000\n",
    "# show graphs statistics\n",
    "print('total graph num: {}, training set: {}'.format(len(graphs),len(graphs_train)))\n",
    "print('max number node: {}'.format(args.max_num_node))\n",
    "print('max/min number edge: {}; {}'.format(max_num_edge,min_num_edge))\n",
    "print('max previous node: {}'.format(args.max_prev_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc5cc46-e760-41b0-84f4-d8280a72f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test graphs saved at:  ./graphs/GraphRNN_RNN_grid_4_128_test_0.dat\n"
     ]
    }
   ],
   "source": [
    "# save ground truth graphs\n",
    "## To get train and test set, after loading you need to manually slice\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_train + '0.dat')\n",
    "save_graph_list(graphs, args.graph_save_path + args.fname_test + '0.dat')\n",
    "print('train and test graphs saved at: ', args.graph_save_path + args.fname_test + '0.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac5587e2-73cc-416d-b230-1f83ae7b314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset initialization\n",
    "if 'nobfs' in args.note:\n",
    "    print('nobfs')\n",
    "    dataset = Graph_sequence_sampler_pytorch_nobfs(graphs_train, max_num_node=args.max_num_node)\n",
    "    args.max_prev_node = args.max_num_node-1\n",
    "if 'barabasi_noise' in args.graph_type:\n",
    "    print('barabasi_noise')\n",
    "    dataset = Graph_sequence_sampler_pytorch_canonical(graphs_train,max_prev_node=args.max_prev_node)\n",
    "    args.max_prev_node = args.max_num_node - 1\n",
    "else:\n",
    "    dataset = Graph_sequence_sampler_pytorch(graphs_train,max_prev_node=args.max_prev_node,max_num_node=args.max_num_node)\n",
    "sample_strategy = torch.utils.data.sampler.WeightedRandomSampler([1.0 / len(dataset) for i in range(len(dataset))],\n",
    "                                                                 num_samples=args.batch_size*args.batch_ratio, replacement=True)\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                                           sampler=sample_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d72db9a7-1d7c-4976-86d9-8767a9ec1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = next(iter(dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8424a3e0-4b6c-43b7-ba47-5bf979342d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 361, 40])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb6aaa4a-6b9a-44a8-a268-ce352bc4410a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 361, 40])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eeb5cc3-0980-4337-83a5-c2f65490f9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([169, 221, 306, 170, 110, 208, 130, 234, 221, 120, 132, 204, 176, 247,\n",
       "        154, 238, 228, 306, 228, 204, 209, 304, 170, 195, 224, 266, 228, 208,\n",
       "        168, 168, 204, 240])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ff441e1-6d62-4665-aba8-75aca6322414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c3f3c-9f33-4b97-867a-34d7cd54ba3d",
   "metadata": {},
   "source": [
    "The structure of the data is a batch of 32 graphs (dim 0), each consisting of up to 360 nodes (dim 1). Each node is represented by an adjacency vector to the nodes in the BFS frontier, with size `max previous node: 40` (dim 2).\n",
    "\n",
    "The x and y datasets should be offset by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "267de0cc-8fbf-46b8-bea6-a9e26f2a3c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['x'][0, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09042ce1-aefa-41be-8952-2c78f1fa3741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['y'][0, 0:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3bc9d5c-c93b-4d0b-8221-34bda5f57ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(test_graph['x'][0, 1:, :], test_graph['y'][0, 0:-1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256bc2a-c6f0-424b-93dd-4d97846aaaa6",
   "metadata": {},
   "source": [
    "So, the representation for each node is an adjacency vector of length 40. What are the SOS and EOS sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e2f38e6-d994-4365-9ca7-ebc160b5d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40., dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['x'][0, 0, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "732adabb-5089-4b7c-ab59-2df410f2ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['y'][0, test_graph['len'][0] - 1, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977bf3d7-e65a-4e41-93fe-306b0e7f22fb",
   "metadata": {},
   "source": [
    "Looks like SOS is all ones and EOS is all zeros. How many total nonzero nodes are there in x and y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb368c4f-54a6-415a-bf93-6b083c88998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(169)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_graph['x'][0, :, :].sum(axis = 1) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05f28b84-2404-47e9-bd01-6d9b43a8b6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(168)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_graph['y'][0, :, :].sum(axis = 1) != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efac18-1e14-4dc5-86ba-19b77b0c1505",
   "metadata": {},
   "source": [
    "As expected, 169 x and 168 y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37e345-3090-4e07-b546-bd13ade444de",
   "metadata": {},
   "source": [
    "Are all the SOS tokens vectors of ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5a5d128-4c54-43ae-81d2-a8616ee90d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
       "        40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40., 40.,\n",
       "        40., 40., 40., 40.], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph['x'][:, 0, :].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a9aca-8112-45fd-878a-0b3eaa1e193d",
   "metadata": {},
   "source": [
    "Looks like it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68282a-757c-4010-85fa-664a99b25cfd",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Train the model (or at least, try to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15942276-0754-4c2e-807c-c4f4d43adc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaca/projects/Comp755-Project-GraphGeneration/GraphRNN/model.py:299: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(param,gain=nn.init.calculate_gain('sigmoid'))\n",
      "/home/alpaca/projects/Comp755-Project-GraphGeneration/GraphRNN/model.py:297: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(param, 0.25)\n",
      "/home/alpaca/projects/Comp755-Project-GraphGeneration/GraphRNN/model.py:302: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     output \u001b[38;5;241m=\u001b[39m MLP_plain(h_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mhidden_size_rnn, embedding_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39membedding_size_output, y_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_prev_node)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphRNN_RNN\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnote:\n\u001b[1;32m     17\u001b[0m     rnn \u001b[38;5;241m=\u001b[39m \u001b[43mGRU_plain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_prev_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_size_rnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mhas_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size_rnn_output\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     output \u001b[38;5;241m=\u001b[39m GRU_plain(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, embedding_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39membedding_size_rnn_output,\n\u001b[1;32m     21\u001b[0m                        hidden_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mhidden_size_rnn_output, num_layers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_layers, has_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m                        has_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m### start training\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/Comp755-Project-GraphGeneration/conda-env/lib/python3.10/site-packages/torch/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/Comp755-Project-GraphGeneration/conda-env/lib/python3.10/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/Comp755-Project-GraphGeneration/conda-env/lib/python3.10/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/projects/Comp755-Project-GraphGeneration/conda-env/lib/python3.10/site-packages/torch/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/Comp755-Project-GraphGeneration/conda-env/lib/python3.10/site-packages/torch/cuda/__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "### model initialization\n",
    "## Graph RNN VAE model\n",
    "# lstm = LSTM_plain(input_size=args.max_prev_node, embedding_size=args.embedding_size_lstm,\n",
    "#                   hidden_size=args.hidden_size, num_layers=args.num_layers).cuda()\n",
    "\n",
    "if 'GraphRNN_VAE_conditional' in args.note:\n",
    "    rnn = GRU_plain(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                    hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                    has_output=False).cuda()\n",
    "    output = MLP_VAE_conditional_plain(h_size=args.hidden_size_rnn, embedding_size=args.embedding_size_output, y_size=args.max_prev_node).cuda()\n",
    "elif 'GraphRNN_MLP' in args.note:\n",
    "    rnn = GRU_plain(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                    hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                    has_output=False).cuda()\n",
    "    output = MLP_plain(h_size=args.hidden_size_rnn, embedding_size=args.embedding_size_output, y_size=args.max_prev_node).cuda()\n",
    "elif 'GraphRNN_RNN' in args.note:\n",
    "    rnn = GRU_plain(input_size=args.max_prev_node, embedding_size=args.embedding_size_rnn,\n",
    "                    hidden_size=args.hidden_size_rnn, num_layers=args.num_layers, has_input=True,\n",
    "                    has_output=True, output_size=args.hidden_size_rnn_output).cuda()\n",
    "    output = GRU_plain(input_size=1, embedding_size=args.embedding_size_rnn_output,\n",
    "                       hidden_size=args.hidden_size_rnn_output, num_layers=args.num_layers, has_input=True,\n",
    "                       has_output=True, output_size=1).cuda()\n",
    "\n",
    "### start training\n",
    "train(args, dataset_loader, rnn, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c4842-cda4-44e9-9c1d-47ffba7b2f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
